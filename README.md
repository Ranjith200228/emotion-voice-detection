# ğŸ¤ Detection of Emotion Using Human Voice

A deep learning-based project that classifies human emotions from voice recordings using audio feature extraction and neural networks. Built with TensorFlow, Keras, and Librosa, this project demonstrates the power of speech emotion recognition for intelligent applications.

---

## ğŸ“Œ Overview

This project focuses on identifying **emotional states** from voice inputs using a **Convolutional Neural Network (CNN)** combined with **LSTM layers**. It uses audio features like **MFCCs (Mel Frequency Cepstral Coefficients)** for training a deep learning model capable of detecting emotions such as Happy, Sad, Angry, Fear, and more.

It includes an **interactive GUI** developed with **Tkinter** for real-time testing of the model.

---

## ğŸ¯ Objectives

- Extract emotion-relevant features from speech audio  
- Train a deep learning model to classify emotions  
- Deploy the model via a user-friendly interface  
- Enable emotion-aware applications and assistive tools

---

## ğŸ§  Key Features

- ğŸ™ï¸ Speech-based input for emotion detection  
- ğŸ§  CNN + LSTM architecture trained on labeled audio data  
- ğŸ“Š Feature extraction using Librosa (MFCCs, Chroma, etc.)  
- ğŸ–¥ï¸ Real-time GUI for emotion prediction using Tkinter  
- ğŸ“ˆ High accuracy on common emotion datasets

---

## ğŸ”§ Tools & Technologies

- **Python**  
- **TensorFlow / Keras** â€“ Model development  
- **Librosa** â€“ Audio signal processing  
- **Tkinter** â€“ GUI development  
- **NumPy / Pandas / Matplotlib** â€“ Data handling & visualization

---



